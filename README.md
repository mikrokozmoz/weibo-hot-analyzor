# å¾®åšçƒ­æœåˆ†æå·¥å…· | Weibo Hot Search Analyzer

ä¸€ä¸ªç”¨äºçˆ¬å–å¾®åšå®æ—¶çƒ­æœè¯é¢˜ã€åˆå¹¶ç»“æœæ•°æ®ã€è¿›è¡Œæ•°æ®åˆ†æå’Œå¤„ç†çš„å®Œæ•´å·¥å…·é“¾ã€‚

*A complete toolkit for crawling Weibo real-time trending topics, merging result data, and performing data analysis and processing.*

> ğŸ”— **åŸºç¡€çˆ¬è™«åº“** | **Base Crawler Library**  
> æœ¬é¡¹ç›®åŸºäº [weibo-search](https://github.com/dataabc/weibo-search) é¡¹ç›®ï¼Œå¹¶ä½¿ç”¨äº†ç»è¿‡ä¿®æ”¹çš„forkç‰ˆæœ¬ [weibo-search (fork)](https://github.com/mikrokozmoz/weibo-search) ä½œä¸ºçˆ¬è™«å¼•æ“ã€‚
> 
> *This project is based on the [weibo-search](https://github.com/dataabc/weibo-search) project, and uses a modified fork version [weibo-search (fork)](https://github.com/mikrokozmoz/weibo-search) as the crawler engine.*

## é¡¹ç›®ç®€ä»‹ | Project Overview

æœ¬é¡¹ç›®å°†å¾®åšçƒ­æœè¯é¢˜çˆ¬å–ã€æ•°æ®èšåˆã€æ•°æ®æ¸…æ´—å’Œåˆ†ææ•´åˆä¸ºä¸€ä¸ªè‡ªåŠ¨åŒ–å·¥ä½œæµã€‚é€šè¿‡ç®€å•çš„å‘½ä»¤è¡Œè„šæœ¬ï¼Œç”¨æˆ·å¯ä»¥å¿«é€Ÿè·å–å¾®åšçƒ­æœæ•°æ®å¹¶è¿›è¡Œæ·±å…¥åˆ†æã€‚

*This project integrates Weibo trending topic crawling, data aggregation, data cleaning, and analysis into an automated workflow. Through simple command-line scripts, users can quickly obtain Weibo trending data and perform in-depth analysis.*

## åŠŸèƒ½ç‰¹æ€§ | Features

- **ç®€å•é…ç½®** âš™ï¸ï¼šæ”¯æŒè¾“å…¥Cookie
- **æ™ºèƒ½åˆå¹¶** ğŸ“Šï¼šè‡ªåŠ¨åˆå¹¶æ‰€æœ‰è¯é¢˜çš„çˆ¬è™«ç»“æœä¸ºç»Ÿä¸€æ•°æ®é›†
- **æ•°æ®å»é‡** âœ¨ï¼šæ”¯æŒè‡ªå®šä¹‰ç›¸ä¼¼åº¦é˜ˆå€¼çš„æ™ºèƒ½å»é‡

<br>

- **Easy Configuration** âš™ï¸: *Support for entering Cookie and custom keyword lists*
- **Smart Merging** ğŸ“Š: *Automatically merge crawler results from all topics into a unified dataset*
- **Data Deduplication** âœ¨: *Support smart deduplication with custom similarity threshold*


## å¿«é€Ÿä¸Šæ‰‹ | Quick Start

### 1. å®‰è£…å’Œç¯å¢ƒé…ç½® | Installation & Setup

```bash
# å…‹éš†é¡¹ç›®
# Clone the project
git clone https://github.com/mikrokozmoz/weibo-hot-analyzor
cd weibo-hot-analyzor

# å®‰è£…ä¾èµ–ï¼ˆä¸€é”®å®‰è£…ï¼‰
# Install all dependencies at once
pip install -r requirements.txt
```

### 2. è·å–çƒ­æœå…³é”®è¯ | Fetch Keywords

```bash
# è‡ªåŠ¨è·å–å¾®åšå½“æ—¥çƒ­æœè¯é¢˜ï¼Œä¿å­˜åˆ° files/keyword_list.txt
# Automatically fetch Weibo trending topics and save to files/keyword_list.txt
python -m weibo_hot_analyzor.fetch_keywords
```

**æ•°æ®æº** | *Data Source*ï¼š  
æœ¬è„šæœ¬ä» [justjavac/weibo-trending-hot-search](https://github.com/justjavac/weibo-trending-hot-search) é¡¹ç›®è·å–æ¯æ—¥æ›´æ–°çš„å¾®åšçƒ­æœæ•°æ®ï¼Œè¯¥é¡¹ç›®æ¯å°æ—¶è‡ªåŠ¨æ›´æ–°ä¸€æ¬¡å¾®åšçƒ­æœæ’è¡Œæ¦œã€‚

*This script fetches daily updated Weibo trending data from the [justjavac/weibo-trending-hot-search](https://github.com/justjavac/weibo-trending-hot-search) project, which automatically updates the Weibo trending list every hour.*

### 3. å¯åŠ¨çˆ¬è™«çˆ¬å–æ•°æ® | Start Crawler

```bash
# å¯åŠ¨çˆ¬è™«è„šæœ¬
# Start the crawler script
python -m weibo_hot_analyzor.post_crawler

# æŒ‰æç¤ºè¾“å…¥ä½ çš„å¾®åšCookieï¼ˆä»æµè§ˆå™¨å¼€å‘è€…å·¥å…·è·å–ï¼‰
# Enter your Weibo Cookie as prompted (obtain from browser developer tools)
```

**æ³¨æ„** | *Note*ï¼š
- çˆ¬è™«ä¼šåœ¨ `weibo-search/ç»“æœæ–‡ä»¶/` ç›®å½•ä¸‹ä¸ºæ¯ä¸ªå…³é”®è¯åˆ›å»ºæ–‡ä»¶å¤¹
- æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼šå¦‚æœçˆ¬è™«ä¸­é€”ä¸­æ–­ï¼Œé‡æ–°è¿è¡Œä¼šç»§ç»­ä»æ–­ç‚¹å¼€å§‹

<br>

- *The crawler will create a folder for each keyword in `weibo-search/ç»“æœæ–‡ä»¶/`*
- *Supports breakpoint resume: if the crawler is interrupted, re-running will continue from the breakpoint*

### 4. åˆå¹¶çˆ¬è™«ç»“æœ | Merge Results

```bash
# å°†æ‰€æœ‰è¯é¢˜çš„CSVæ–‡ä»¶åˆå¹¶æˆä¸€ä¸ªï¼Œè‡ªåŠ¨æ·»åŠ "å…³é”®è¯"åˆ—
# Merge all topic CSV files into one, automatically add "keyword" column
python -m weibo_hot_analyzor.merge_results
```

è¾“å‡ºæ–‡ä»¶ï¼š`files/data_raw.csv`  
*Output file: `files/data_raw.csv`*

### 5. æ•°æ®å»é‡ | Deduplication

```bash
# å¯åŠ¨æ•°æ®å»é‡è„šæœ¬
# Start data deduplication script
python -m weibo_hot_analyzor.analyze --dedup

# æŒ‰æç¤ºè¾“å…¥ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0-1ï¼‰
# æ¨èå€¼: 0.75-0.95ï¼Œé»˜è®¤å€¼: 0.88
# Enter similarity threshold (0-1) as prompted
# Recommended: 0.75-0.95, Default: 0.88
```

è¾“å‡ºæ–‡ä»¶ï¼š`files/data_deduped.csv`  
*Output file: `files/data_deduped.csv`*

## å…³é”®è¯è¯´æ˜ | Configuration Details

### ç›¸ä¼¼åº¦é˜ˆå€¼ | Similarity Threshold

åœ¨å»é‡è¿‡ç¨‹ä¸­ï¼Œç›¸ä¼¼åº¦é˜ˆå€¼æ§åˆ¶å»é‡çš„ä¸¥æ ¼ç¨‹åº¦ï¼š

*During deduplication, the similarity threshold controls the strictness of deduplication:*

| é˜ˆå€¼èŒƒå›´ | è¯´æ˜ | å»ºè®®åœºæ™¯ |
|---------|------|--------|
| 0.70-0.80 | å®½æ¾å»é‡ï¼Œç§»é™¤æ›´å¤šé‡å¤ | éœ€è¦é«˜è´¨é‡å”¯ä¸€å†…å®¹çš„åˆ†æ |
| 0.80-0.90 | å¹³è¡¡å»é‡ï¼Œæ¨èä½¿ç”¨ | ä¸€èˆ¬æ•°æ®åˆ†æ |
| 0.90-0.99 | ä¸¥æ ¼å»é‡ï¼Œç§»é™¤è¾ƒå°‘é‡å¤ | ä¿ç•™ç»†å¾®å·®å¼‚å†…å®¹ |

| Threshold Range | Description | Recommended Scenario |
|---------|------|--------|
| 0.70-0.80 | Loose dedup, remove more duplicates | Analysis requiring high-quality unique content |
| 0.80-0.90 | Balanced dedup, recommended | General data analysis |
| 0.90-0.99 | Strict dedup, remove fewer duplicates | Preserve subtle differences in content |

## ä¾èµ–é¡¹ | Dependencies

### ä¸»è¦åº“ | Main Libraries

- **Python 3.7+**
- **pandas** - æ•°æ®å¤„ç† / Data processing
- **scrapy** - ç½‘ç»œçˆ¬è™«æ¡†æ¶ / Web scraping framework
- **jieba** - ä¸­æ–‡åˆ†è¯ / Chinese word segmentation
- **wordcloud** - è¯äº‘ç”Ÿæˆ / Word cloud generation
- **matplotlib** - æ•°æ®å¯è§†åŒ– / Data visualization
- **requests** - HTTPè¯·æ±‚ / HTTP requests

### Submoduleä¾èµ– | Submodule Dependencies

æœ¬é¡¹ç›®é›†æˆäº†ä¸¤ä¸ªé‡è¦çš„submoduleï¼š

*This project integrates two important submodules:*

- **[weibo-search](https://github.com/mikrokozmoz/weibo-search)** - å¾®åšçˆ¬è™«æ¡†æ¶ / Weibo crawler framework
- **[weibo-posts-processing](https://github.com/mikrokozmoz/weibo-posts-processing)** - å¾®åšæ•°æ®å¤„ç†åº“ / Weibo data processing library

Submoduleä¼šåœ¨è„šæœ¬é¦–æ¬¡è¿è¡Œæ—¶è‡ªåŠ¨åˆå§‹åŒ–ï¼Œæ— éœ€æ‰‹åŠ¨æ“ä½œã€‚

*Submodules will be automatically initialized when the script runs for the first time, no manual operation required.*

## æ–‡ä»¶è¯´æ˜ | File Descriptions

| æ¨¡å— | è¯´æ˜ | ä½¿ç”¨åœºæ™¯ |
|------|------|--------|
| `weibo_hot_analyzor.fetch_keywords` | è·å–å¾®åšå®æ—¶çƒ­æœè¯é¢˜ | å®šæœŸæ›´æ–°å…³é”®è¯åˆ—è¡¨ |
| `weibo_hot_analyzor.post_crawler` | çˆ¬è™«å¯åŠ¨è„šæœ¬ï¼Œè‡ªåŠ¨åˆå§‹åŒ–weibo-searchæ¨¡å— | æ—¥å¸¸çˆ¬å–æ•°æ® |
| `weibo_hot_analyzor.merge_results` | åˆå¹¶çˆ¬è™«ç»“æœä¸ºç»Ÿä¸€æ•°æ®é›† | çˆ¬è™«å®Œæˆåå¤„ç†ç»“æœ |
| `weibo_hot_analyzor.analyze` | æ•°æ®åˆ†æè„šæœ¬ï¼Œæ”¯æŒå»é‡ç­‰æ“ä½œ | æ•°æ®æ¸…æ´—å’Œåˆæ­¥åˆ†æ |

| Module | Description | Use Case |
|------|------|--------|
| `weibo_hot_analyzor.fetch_keywords` | Fetch Weibo real-time trending topics | Regularly update keyword list |
| `weibo_hot_analyzor.post_crawler` | Crawler startup script, auto-initialize weibo-search module | Daily data crawling |
| `weibo_hot_analyzor.merge_results` | Merge crawler results into unified dataset | Process results after crawling |
| `weibo_hot_analyzor.analyze` | Data analysis script, support deduplication operations | Data cleaning and initial analysis |

## å·¥ä½œæµç¨‹ | Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. python -m weibo_hot_analyzor.fetch_keywords - è·å–çƒ­æœå…³é”®è¯      â”‚
â”‚    Get trending keywords from Weibo                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. python -m weibo_hot_analyzor.post_crawler - çˆ¬å–æ•°æ®              â”‚
â”‚    Crawl data with custom Cookie and similarity threshold            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. python -m weibo_hot_analyzor.merge_results - åˆå¹¶ç»“æœ             â”‚
â”‚    Merge all topic results into data_raw.csv                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. python -m weibo_hot_analyzor.analyze --dedup - æ•°æ®å»é‡           â”‚
â”‚    Deduplicate data with custom threshold                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## å¸¸è§é—®é¢˜ | FAQ

**Q: æˆ‘éœ€è¦è¾“å…¥Cookieå—ï¼Ÿ**  
*Q: Do I need to enter a Cookie?*

A: æ˜¯çš„ï¼Œéœ€è¦ä»æµè§ˆå™¨è·å–å¾®åšçš„Cookieï¼Œä»¥ä¾¿çˆ¬è™«èƒ½æ­£å¸¸è®¿é—®ã€‚æ­¥éª¤ï¼š
1. æ‰“å¼€ weibo.comï¼Œç™»å½•ä½ çš„è´¦å·
2. æŒ‰ F12 æ‰“å¼€å¼€å‘è€…å·¥å…·
3. åœ¨ Network æ ‡ç­¾ä¸­æ‰¾ä»»æ„è¯·æ±‚ï¼Œå¤åˆ¶ Request Headers ä¸­çš„ Cookie å€¼
4. è¿è¡Œçˆ¬è™«æ—¶ï¼Œä¼šå¼¹å‡ºæç¤ºè¾“å…¥Cookieï¼Œç²˜è´´å³å¯

**Cookie ä¼šè¢«ä¿å­˜å—ï¼Ÿ**  
*Will the Cookie be saved?*

A: ä¼šçš„ï¼ç¬¬ä¸€æ¬¡è¾“å…¥Cookieåï¼Œç¨‹åºä¼šè‡ªåŠ¨å°†å…¶ä¿å­˜åˆ° `weibo-search/weibo/settings.py` ä¸­ã€‚ä¹‹åæ¯æ¬¡è¿è¡Œçˆ¬è™«æ—¶ï¼š
- å¦‚æœç›´æ¥æŒ‰ Enterï¼ˆä¸è¾“å…¥ä»»ä½•å†…å®¹ï¼‰ï¼Œä¼šè‡ªåŠ¨ä½¿ç”¨ä¸Šæ¬¡ä¿å­˜çš„Cookie
- å¦‚æœéœ€è¦æ›´æ¢Cookieï¼Œé‡æ–°è¾“å…¥æ–°çš„Cookieå³å¯ï¼Œä¼šè‡ªåŠ¨è¦†ç›–æ—§å€¼

*Yes! After entering the Cookie for the first time, the program will automatically save it to `weibo-search/weibo/settings.py`. Each subsequent crawler run:*
- *If you just press Enter (without entering anything), it will automatically use the previously saved Cookie*
- *If you need to change the Cookie, simply enter a new one, which will automatically replace the old value*

**A: Yes, you need to obtain Weibo's Cookie from your browser for the crawler to access normally. Steps:*
1. *Open weibo.com and log in*
2. *Press F12 to open developer tools*
3. *In the Network tab, find any request and copy the Cookie value from Request Headers*
4. *When running the crawler, a prompt will appear to enter the Cookie, just paste it*

## è®¸å¯è¯ | License

MIT License

## è´¡çŒ® | Contributing

æ¬¢è¿æäº¤ issue æˆ– pull requestï¼

*Contributions are welcome via issues or pull requests!*

## ç›¸å…³é¡¹ç›® | Related Projects

- [weibo-search](https://github.com/mikrokozmoz/weibo-search) - å¾®åšçˆ¬è™«æ¡†æ¶
- [weibo-posts-processing](https://github.com/mikrokozmoz/weibo-posts-processing) - å¾®åšæ•°æ®å¤„ç†åº“
- [weibo-trending-hot-search](https://github.com/justjavac/weibo-trending-hot-search) - å¾®åšçƒ­æœæ€»ç»“
