#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
åˆå¹¶çˆ¬è™«ç»“æœï¼šå°†æ‰€æœ‰è¯é¢˜çš„CSVæ–‡ä»¶åˆå¹¶æˆä¸€ä¸ªæ€»çš„CSVæ–‡ä»¶
Merge crawler results: Combine all topic CSV files into one master CSV file
"""

import os
import sys
import pandas as pd
from pathlib import Path

def merge_crawler_results():
    """åˆå¹¶çˆ¬è™«ç»“æœæ–‡ä»¶"""
    results_dir = 'weibo-search/ç»“æœæ–‡ä»¶'
    output_dir = 'files'
    
    # æ£€æŸ¥ç»“æœç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(results_dir):
        print(f"âŒ æ‰¾ä¸åˆ°ç»“æœç›®å½•: {results_dir}")
        print(f"âŒ Results directory not found: {results_dir}")
        sys.exit(1)
    
    # è·å–æ‰€æœ‰å­æ–‡ä»¶å¤¹
    folders = [f for f in os.listdir(results_dir) 
               if os.path.isdir(os.path.join(results_dir, f))]
    
    if not folders:
        print(f"âš ï¸  ç»“æœç›®å½•ä¸ºç©º")
        print(f"âš ï¸  Results directory is empty")
        sys.exit(1)
    
    print(f"ğŸ“ æ‰¾åˆ° {len(folders)} ä¸ªç»“æœæ–‡ä»¶å¤¹")
    print(f"ğŸ“ Found {len(folders)} result folders\n")
    
    dfs = []
    
    for folder in folders:
        # åªåˆ é™¤å‰åçš„%23ï¼Œä¿ç•™ä¸­é—´çš„%23ï¼ˆé˜²æ­¢æ•°å­—å¼€å¤´æˆ–å«æœ‰%23çš„è¯é¢˜è¢«æˆªæ–­ï¼‰
        keyword = folder.lstrip('%23').rstrip('%23')
        
        # CSVæ–‡ä»¶è·¯å¾„
        csv_path = os.path.join(results_dir, folder, f"{folder}.csv")
        
        if not os.path.exists(csv_path):
            print(f"âš ï¸  æ‰¾ä¸åˆ°CSVæ–‡ä»¶: {csv_path}")
            print(f"âš ï¸  CSV file not found: {csv_path}")
            continue
        
        try:
            # è¯»å–CSVæ–‡ä»¶
            df = pd.read_csv(csv_path, encoding='utf-8')
            
            # æ·»åŠ å…³é”®è¯åˆ—
            df['å…³é”®è¯'] = keyword
            
            dfs.append(df)
            print(f"âœ… å·²è¯»å–: {keyword}")
            print(f"âœ… Loaded: {keyword} ({len(df)} rows)")
        except Exception as e:
            print(f"âŒ è¯»å–å¤±è´¥: {csv_path}")
            print(f"âŒ Failed to read: {csv_path} - {e}")
    
    if not dfs:
        print("âŒ æ²¡æœ‰æˆåŠŸè¯»å–ä»»ä½•CSVæ–‡ä»¶")
        print("âŒ No CSV files were successfully read")
        sys.exit(1)
    
    # åˆå¹¶æ‰€æœ‰æ•°æ®æ¡†
    print("\nğŸ”— åˆå¹¶æ•°æ®ä¸­...")
    print("ğŸ”— Merging data...")
    merged_df = pd.concat(dfs, ignore_index=True)
    
    # ä¿å­˜ä¸ºCSV
    output_path = os.path.join(output_dir, 'data_raw.csv')
    os.makedirs(output_dir, exist_ok=True)
    
    try:
        merged_df.to_csv(output_path, index=False, encoding='utf-8')
        print(f"\nâœ… æ•°æ®å·²ä¿å­˜: {output_path}")
        print(f"âœ… Data saved: {output_path}")
        print(f"ğŸ“Š æ€»å…± {len(merged_df)} æ¡æ•°æ®ï¼Œ{len(merged_df.columns)} åˆ—")
        print(f"ğŸ“Š Total {len(merged_df)} rows, {len(merged_df.columns)} columns")
    except Exception as e:
        print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
        print(f"âŒ Failed to save: {e}")
        sys.exit(1)

if __name__ == "__main__":
    print("=" * 50)
    print("åˆå¹¶çˆ¬è™«ç»“æœ")
    print("Merge Crawler Results")
    print("=" * 50 + "\n")
    
    merge_crawler_results()
